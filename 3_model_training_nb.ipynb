{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea668df1",
   "metadata": {},
   "source": [
    "# Training a Model\n",
    "\n",
    "Now that I've got data in Hopsworks and the architecture for updating it, I can go ahead and start the process of constructing training data and then training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a36d146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/14486\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e49a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature group.\n",
    "zip_code = '60603'  # Chicago\n",
    "country_code = 'US'\n",
    "city = 'Chicago'\n",
    "\n",
    "fg_name = f'aqi_{city}_{zip_code}'.lower()\n",
    "\n",
    "aqi_online_fg = fs.get_feature_group(fg_name, version=1)\n",
    "\n",
    "not_features = ['date', 'lat', 'lon']\n",
    "\n",
    "ds_query = aqi_online_fg.select_except(not_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486e38c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>so2</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>pm10</th>\n",
       "      <th>nh3</th>\n",
       "      <th>datetime</th>\n",
       "      <th>aqi</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>347.14</td>\n",
       "      <td>10.39</td>\n",
       "      <td>21.94</td>\n",
       "      <td>39.70</td>\n",
       "      <td>8.46</td>\n",
       "      <td>7.21</td>\n",
       "      <td>11.43</td>\n",
       "      <td>2.69</td>\n",
       "      <td>2020-11-28 12:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>440.60</td>\n",
       "      <td>16.99</td>\n",
       "      <td>26.39</td>\n",
       "      <td>26.82</td>\n",
       "      <td>10.97</td>\n",
       "      <td>18.80</td>\n",
       "      <td>24.32</td>\n",
       "      <td>4.37</td>\n",
       "      <td>2020-12-03 12:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340.46</td>\n",
       "      <td>5.03</td>\n",
       "      <td>25.36</td>\n",
       "      <td>42.20</td>\n",
       "      <td>10.97</td>\n",
       "      <td>16.63</td>\n",
       "      <td>19.86</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2020-12-03 16:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273.71</td>\n",
       "      <td>0.02</td>\n",
       "      <td>14.91</td>\n",
       "      <td>41.84</td>\n",
       "      <td>5.42</td>\n",
       "      <td>11.97</td>\n",
       "      <td>13.51</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2020-12-04 06:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>243.66</td>\n",
       "      <td>1.02</td>\n",
       "      <td>11.31</td>\n",
       "      <td>80.11</td>\n",
       "      <td>4.71</td>\n",
       "      <td>1.38</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2020-12-05 12:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       co     no    no2     o3    so2  pm2_5   pm10   nh3            datetime  \\\n",
       "0  347.14  10.39  21.94  39.70   8.46   7.21  11.43  2.69 2020-11-28 12:00:00   \n",
       "1  440.60  16.99  26.39  26.82  10.97  18.80  24.32  4.37 2020-12-03 12:00:00   \n",
       "2  340.46   5.03  25.36  42.20  10.97  16.63  19.86  2.50 2020-12-03 16:00:00   \n",
       "3  273.71   0.02  14.91  41.84   5.42  11.97  13.51  0.63 2020-12-04 06:00:00   \n",
       "4  243.66   1.02  11.31  80.11   4.71   1.38   2.84  0.76 2020-12-05 12:00:00   \n",
       "\n",
       "   aqi   id  \n",
       "0    1   36  \n",
       "1    2  156  \n",
       "2    2  160  \n",
       "3    2  174  \n",
       "4    2  204  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_query.show(5, online=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979bab66",
   "metadata": {},
   "source": [
    "Notice that the data appears to be out of order. This is ok."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f091150",
   "metadata": {},
   "source": [
    "I will now define some transformation functions to standardize all of our features. These transformations will be applied to the data when I create a feature view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3557f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformation function we want.\n",
    "standard_scaler = fs.get_transformation_function(name=\"standard_scaler\")\n",
    "\n",
    "# Map features to transformation function\n",
    "transformation_functions = {\n",
    "    'co': standard_scaler, \n",
    "    'no': standard_scaler, \n",
    "    'no2': standard_scaler, \n",
    "    'o3': standard_scaler,\n",
    "    'so2': standard_scaler, \n",
    "    'pm2_5': standard_scaler, \n",
    "    'pm10': standard_scaler, \n",
    "    'nh3': standard_scaler\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df6e98",
   "metadata": {},
   "source": [
    "Training data is created from feature views in Hopsworks. Feature views are logical views over sets of features. Normally they are created by joining together different feature groups. Since I only have one here though it's a little different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "948ad530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/14486/fs/14406/fv/aqi_chicago_60603_fv/version/1\n"
     ]
    }
   ],
   "source": [
    "fv_name = f'{fg_name}_fv'\n",
    "\n",
    "try:\n",
    "    feature_view = fs.get_feature_view(name=fv_name, version=1)\n",
    "except: \n",
    "    feature_view = fs.create_feature_view(\n",
    "    name=fv_name,\n",
    "    version=1,\n",
    "    description='feature view for creating training data',\n",
    "    query=ds_query,\n",
    "    labels=['aqi', 'id'],  # not using ID as a label, just for keeping track of data order\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b51963d",
   "metadata": {},
   "source": [
    "Now let's get the earliest and latest dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a88e84a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-27 00:00:00 2023-01-19 14:00:00\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "end_date = pd.to_datetime(fs.sql(f\"SELECT MAX(`datetime`) FROM `{fg_name}_1`\", online=True).values[0][0])\n",
    "start_date = pd.to_datetime(fs.sql(f\"SELECT MIN(`datetime`) FROM `{fg_name}_1`\", online=True).values[0][0])\n",
    "\n",
    "print(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1325da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-27 00:00:00 2023-01-19 14:00:00\n"
     ]
    }
   ],
   "source": [
    "start_date_str = start_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(start_date_str, end_date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "202179f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/14486/jobs/named/aqi_chicago_60603_fv_1_1_create_fv_td_21012023210052/executions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `1`.\n"
     ]
    }
   ],
   "source": [
    "# # Create training datasets based event time filter\n",
    "train_d, train_d_job = feature_view.create_training_data(\n",
    "        start_time = start_date_str,\n",
    "        end_time = end_date_str,    \n",
    "        description = f'aqi data for training {start_date_str} to {end_date_str}',\n",
    "        data_format = \"csv\",\n",
    "        coalesce = True,\n",
    "        write_options = {'wait_for_job': False},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d016b2fe",
   "metadata": {},
   "source": [
    "I'm going to use a portion of the dataset for normal training as well as evaluating the model with cross validation. Because of all this I'm not creating a separate training and testing set with Hopsworks's API.\n",
    "\n",
    "Scikit-Learn has convenient functions for splitting time series data into validation sets, which I'll do later. For now, I just put all the data into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = feature_view.get_training_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161055af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e71ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check that we have the right time period for train and test\n",
    "print(train_x['datetime'].min(), train_x['datetime'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87840d",
   "metadata": {},
   "source": [
    "I'm still not sure why Hopsworks is returning the wrong subset of data. The dates are correct, but the times are getting converted to 12-hour time either when I create the training set or get the training set. You can see above that the beginning time is 12:00PM rather than 12:00AM (or 00:00 as I specified) and the ending time is 2:00AM rather than 2:00PM (I specified 14:00)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f112f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026b87a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to convert datetime from strings\n",
    "train_x.datetime = pd.to_datetime(train_x.datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d4eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c65fc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data points are not in order\n",
    "train_x = train_x.sort_values(\"datetime\")\n",
    "train_y = train_y.reindex(train_x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fc6c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x['datetime'].min(), train_x['datetime'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc217a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to remove time zone information\n",
    "train_x['datetime'] = train_x['datetime'].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x['datetime'].min(), train_x['datetime'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dad5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the datetime as index now\n",
    "train_x = train_x.reset_index(drop=True)\n",
    "train_x = train_x.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.reset_index(drop=True)\n",
    "train_y = train_y.set_index(train_x.index)\n",
    "train_y['aqi'] = train_y['aqi']-1  # xgboost requires zero indexed categories for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1241cd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1be3a9",
   "metadata": {},
   "source": [
    "Now that the data is all cleaned up, I want to combine it all into a single dataframe. I'll call it `df` just so I don't get it confused between training, testing, validation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat\n",
    "df = pd.concat([train_x, train_y], axis=1)\n",
    "df = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acdf466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_y.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03087672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['hour'] = df.index.hour\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    df['dayofmonth'] = df.index.day\n",
    "    df['weekofyear'] = df.index.isocalendar().week\n",
    "    return df\n",
    "\n",
    "df = create_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c91499",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44174d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1467f0e9",
   "metadata": {},
   "source": [
    "## Modeling with XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943d42d",
   "metadata": {},
   "source": [
    "Now that I have data to train a model, I want to spend some time talking about model evaluation before I actually dive into training.\n",
    "\n",
    "The target variable here is the air quality index (AQI), and in this case it ranges from (0 to 4) and is integral (the actual indices are 1 to 5, but I have to change it to 0 to 4 because XGBoost requires 0-indexed categories). Because of the integer constraint, I'm going to pose this machine learning task as a classification one. This will get rid of the need for rounding predictions to the nearest integer, but it also means I need to think a little bit more carefully about evaluating the model.\n",
    "\n",
    "In classification tasks, model evaluation is extremely important. A common metric for evaluating classification models is accuracy. However, using that metric can cause modelers to fall into a trap of thinking a model is good, when in fact it's not doing any better than just guessing. For example, if I were to flip a fair coin 100 times, and then guess every time that the coin had landed on heads, I would have an accuracy of around 50%. Even though I just guessed every time, I still got an accuracy around 50%. In that case, a machine learning classifier would need to have an accuracy *greater than* 50% to be considered useful. That 50% accuracy is known as a baseline metric. This scenario gets more complicated when there are multiple classes and the classes are not balanced. \n",
    "\n",
    "The dataset at hand has a class imbalance, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d16723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['aqi'].value_counts()/len(df['aqi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44518209",
   "metadata": {},
   "source": [
    "Say I just guess 0 (remember that's actually an AQI of 1) every time. Then I'll be correct 47.6% of the time. So I need to have a model that is correct more than that. What if I guess randomly, weighted by the share of the distribution each class has? That'll be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "((df['aqi'].value_counts()/len(df['aqi']))**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9ed158",
   "metadata": {},
   "source": [
    "So basically, if I'm using accuracy as a metric to evaluate the model, I need to do better than 37.9% to be confident that the model is better than randomly guessing, and better than 47.6% to be better than just guessing the most common value. This is why accuracy is a misleading metric. A better metric to use would be the log-loss function. \n",
    "\n",
    "Recall that predictions with classifiers are made using probabilities, that is, the probability that a given record belongs to a particular class. For example in a binary classification problem, we predict the probablility that a record belongs to the positive class. The log-loss function measures how close a prediction probability is to the corresponding true value. The more a predicted probability diverges from the actual value, the higher the log-loss value is. In other words, a poorer prediction gets a higher log-loss score than a better one. \n",
    "\n",
    "The log-loss function $L\\big(\\hat{p}^{(i)}\\big)$ is as follows for a two-class classification, where $\\hat{p}^{(i)}$ is the probability that a given record belongs to the positive class and $y^{(i)}$ is the class (0 or 1):\n",
    "$$L\\big(\\hat{p}^{(i)}\\big)=-\\Big(y^{(i)}\\log\\big(\\hat{p}^{(i)}\\big)+\\big(1-y^{(i)}\\big)\\log\\big(1-\\hat{p}^{(i)}\\big)\\Big)$$\n",
    "\n",
    "If I plot this for the positive class, $y^{(i)}=1$, we can see that poorer predictions are heavily penalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ac509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 50\n",
    "probs = np.linspace(0.01, 0.99, num=n)\n",
    "y = np.full(n, 1, dtype=int)\n",
    "\n",
    "def logloss(p, y):\n",
    "    one = y * np.log(probs)\n",
    "    two = (1-y)*np.log(1-probs)\n",
    "    \n",
    "    return -1*(one+two)\n",
    "\n",
    "plt.plot(probs, logloss(probs, y), marker='o', color='r', label='Positive Class')\n",
    "plt.legend()\n",
    "plt.title('Log Loss of Prediction Probabilities \\nfor a Positive (1) Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addf2946",
   "metadata": {},
   "source": [
    "The log-loss metric is provided as a function in Scikit-Learn, which averages the log-loss for every record in the dataset.\n",
    "\n",
    "Now the question is, what's the baseline log-loss for our dataset? Also, what is the log-loss when I just randomly predict the class, weighted by the share of each class in the distribution?\n",
    "\n",
    "The baseline log-loss will be the log-loss when I predict a probability of a record belonging to the positive class 48% of the time, since the most prevalent class has a 48% share of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165ccc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "probs = np.full(n, 0.48, dtype=float)\n",
    "y = np.concatenate((np.full(48, 1, dtype=float), np.full(52, 0, dtype=float)))\n",
    "\n",
    "logloss(probs, y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0187e350",
   "metadata": {},
   "source": [
    "So I need a log-loss less than 0.69 for the model to be considered better than guessing 0 every time. Now what is the log loss when we just randomly predict the class, weighted by the share of each class in the distribution? That would just be the average of the log-losses for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3619a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def calculate_log_loss(class_ratio, multi=10000):\n",
    "    \n",
    "    if sum(class_ratio)!=1.0:\n",
    "        print(\"warning: Sum of ratios should be 1 for best results\")\n",
    "        class_ratio[-1]+=1-sum(class_ratio)  # add the residual to last class's ratio\n",
    "    \n",
    "    actuals=[]\n",
    "    for i,val in enumerate(class_ratio):\n",
    "        actuals=actuals+[i for x in range(int(val*multi))]\n",
    "        \n",
    "\n",
    "    preds=[]\n",
    "    for i in range(multi):\n",
    "        preds+=[class_ratio]\n",
    "\n",
    "    return (log_loss(actuals, preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_log_loss([0.48, 0.38, 0.07, 0.06, 0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9c07d4",
   "metadata": {},
   "source": [
    "So now I have an upper bound on the log-loss to determine if my model is worth it: 0.69. Now I can go ahead and start training the model.\n",
    "\n",
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3a681e",
   "metadata": {},
   "source": [
    "Alright, so I need to do a little bit of preprocessing. I need to make some cross validation folds so that I can find the best model. After training, I'll write a function to compute some lag features so that I can make predictions into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f4ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a2cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits=3, test_size=24*90*1, gap=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(15,15), sharex=True)\n",
    "\n",
    "fold = 0\n",
    "for train_idx, val_idx in tss.split(df):\n",
    "    train_val = df.iloc[train_idx]\n",
    "    test_val = df.iloc[val_idx]\n",
    "    train_val['aqi'].plot(ax=axs[fold], \n",
    "                          label='Training Set', \n",
    "                          title=f'Cross Validation Fold {fold} Data Train/Test')\n",
    "    test_val['aqi'].plot(ax=axs[fold], \n",
    "                          label='Test Set')\n",
    "    axs[fold].axvline(test_val.index.min(), color='black', ls='--')\n",
    "    fold += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180c88a",
   "metadata": {},
   "source": [
    "### Forecasting Horizon\n",
    "\n",
    "I want to predict data 3 days into the future. Thus the forecasting horizon will be 3 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4425a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lags(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    target_map = df['aqi'].to_dict()\n",
    "    df['aqi_lag3'] = (df.index - pd.Timedelta('3 days')).map(target_map)\n",
    "    df['aqi_lag6'] = (df.index - pd.Timedelta('6 days')).map(target_map)\n",
    "    df['aqi_lag9'] = (df.index - pd.Timedelta('9 days')).map(target_map)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_lags(df).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa09d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ec9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekofyear'] = df['weekofyear'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186bb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc705c",
   "metadata": {},
   "source": [
    "### Train with Cross Validation\n",
    "\n",
    "Use cross validation to find some good parameters for the model without overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5926894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979d5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "preds = []\n",
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in tss.split(df):\n",
    "    train = df.iloc[train_idx]\n",
    "    test = df.iloc[val_idx]\n",
    "    \n",
    "    features = ['hour', 'dayofweek', 'quarter', 'month', \n",
    "                'year', 'dayofyear', 'dayofmonth', 'weekofyear', 'aqi_lag3', 'aqi_lag6', 'aqi_lag9']\n",
    "    target = 'aqi'\n",
    "    \n",
    "    x_train = train[features]\n",
    "    y_train = train[target]\n",
    "    \n",
    "    x_test = test[features]\n",
    "    y_test = test[target]\n",
    "    \n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=train[target])\n",
    "\n",
    "    clf = xgb.XGBClassifier(n_estimators=1500, \n",
    "                            booster='gbtree',\n",
    "                            early_stopping_rounds=50,\n",
    "                            max_depth=3,\n",
    "                            learning_rate=0.005)\n",
    "    clf.fit(x_train, y_train,\n",
    "            eval_set=[(x_train, y_train), (x_test, y_test)],\n",
    "            verbose=100,\n",
    "#             sample_weight=sample_weights\n",
    "    )\n",
    "    \n",
    "    y_pred = clf.predict_proba(x_test)\n",
    "    preds.append(y_pred)\n",
    "    score = log_loss(y_test, y_pred)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b58da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CV Fold Scores: ', scores)\n",
    "print(f'Average Score: {np.mean(scores):0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e1cfe",
   "metadata": {},
   "source": [
    "### Retraining with Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126996a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['hour', 'dayofweek', 'quarter', 'month', \n",
    "            'year', 'dayofyear', 'dayofmonth', 'weekofyear', 'aqi_lag3', 'aqi_lag6', 'aqi_lag9']\n",
    "target = 'aqi'\n",
    "\n",
    "x_all = df[features]\n",
    "y_all = df[target]\n",
    "\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', \n",
    "                                       y=df[target])\n",
    "\n",
    "clf = xgb.XGBClassifier(n_estimators=1500, \n",
    "                        booster='gbtree',\n",
    "                        early_stopping_rounds=50,\n",
    "                        max_depth=3,\n",
    "                        learning_rate=0.005)\n",
    "\n",
    "clf.fit(x_all, y_all, eval_set=[(x_all, y_all)], \n",
    "        verbose=100, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5178bf",
   "metadata": {},
   "source": [
    "### Making Future DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aacf2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_start = df.index.max()\n",
    "future_end = future_start + pd.Timedelta('3 days') - pd.Timedelta('1 hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9518c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = pd.date_range(future_start, future_end, freq='1h')\n",
    "future_df = pd.DataFrame(index=future)\n",
    "future_df['isFuture'] = True\n",
    "df['isFuture'] = False\n",
    "\n",
    "df_and_future = pd.concat([df, future_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591e7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_and_future = add_lags(df_and_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_w_features = df_and_future.query('isFuture').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771bc0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_w_features = create_features(future_w_features)\n",
    "future_w_features['weekofyear'] = future_w_features['weekofyear'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c499c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_w_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_w_features['aqi_lag9'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(future_w_features[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5016cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ee641",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({'feature_importance': clf.feature_importances_}, index=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92749d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceccec9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
