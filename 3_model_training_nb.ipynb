{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea668df1",
   "metadata": {},
   "source": [
    "# Training a Model\n",
    "\n",
    "Now that we've got data in Hopsworks and the architecture for updating it, we can go ahead and start writing our model training data. Since we're working with time series data that has strong seasonality, I'm going to use Meta's Prophet algorithm.\n",
    "\n",
    "Since our data is hosted on Hopsworks, we need to get it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a36d146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/14486\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "457ecb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature groups.\n",
    "zip_code = '60603'  # Chicago\n",
    "country_code = 'US'\n",
    "city = 'Chicago'\n",
    "\n",
    "fg_name = f'aqi_{city}_{zip_code}'.lower()\n",
    "\n",
    "aqi_online_fg = fs.get_feature_group(fg_name, version=1)\n",
    "\n",
    "not_features = ['date', 'lat', 'lon', 'id']\n",
    "\n",
    "ds_query = aqi_online_fg.select_except(not_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1211de08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>so2</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>pm10</th>\n",
       "      <th>nh3</th>\n",
       "      <th>datetime</th>\n",
       "      <th>aqi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>343.80</td>\n",
       "      <td>0.47</td>\n",
       "      <td>31.19</td>\n",
       "      <td>13.77</td>\n",
       "      <td>5.13</td>\n",
       "      <td>9.09</td>\n",
       "      <td>12.33</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2020-11-27 05:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12.85</td>\n",
       "      <td>57.22</td>\n",
       "      <td>5.19</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2020-11-30 17:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>417.23</td>\n",
       "      <td>11.06</td>\n",
       "      <td>40.44</td>\n",
       "      <td>33.98</td>\n",
       "      <td>13.23</td>\n",
       "      <td>12.01</td>\n",
       "      <td>17.45</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2020-12-02 16:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487.33</td>\n",
       "      <td>14.08</td>\n",
       "      <td>41.13</td>\n",
       "      <td>15.02</td>\n",
       "      <td>9.66</td>\n",
       "      <td>19.76</td>\n",
       "      <td>25.85</td>\n",
       "      <td>5.26</td>\n",
       "      <td>2020-12-03 10:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>460.63</td>\n",
       "      <td>4.08</td>\n",
       "      <td>55.52</td>\n",
       "      <td>3.89</td>\n",
       "      <td>7.87</td>\n",
       "      <td>21.90</td>\n",
       "      <td>27.35</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2020-12-07 07:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       co     no    no2     o3    so2  pm2_5   pm10   nh3            datetime  \\\n",
       "0  343.80   0.47  31.19  13.77   5.13   9.09  12.33  0.68 2020-11-27 05:00:00   \n",
       "1  240.33   0.05  12.85  57.22   5.19   1.07   2.38  0.76 2020-11-30 17:00:00   \n",
       "2  417.23  11.06  40.44  33.98  13.23  12.01  17.45  3.04 2020-12-02 16:00:00   \n",
       "3  487.33  14.08  41.13  15.02   9.66  19.76  25.85  5.26 2020-12-03 10:00:00   \n",
       "4  460.63   4.08  55.52   3.89   7.87  21.90  27.35  1.84 2020-12-07 07:00:00   \n",
       "\n",
       "   aqi  \n",
       "0    1  \n",
       "1    1  \n",
       "2    2  \n",
       "3    2  \n",
       "4    3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_query.show(5, online=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a571d4",
   "metadata": {},
   "source": [
    "Notice that the data appears to be out of order. This is ok."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1f1f4",
   "metadata": {},
   "source": [
    "We will now define some transformation functions to normalize all of our features. These transformations will be applied to the data when we create a feature view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12688d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformation function we want.\n",
    "standard_scaler = fs.get_transformation_function(name=\"standard_scaler\")\n",
    "\n",
    "# Map features to transformation function\n",
    "transformation_functions = {\n",
    "    'co': standard_scaler, \n",
    "    'no': standard_scaler, \n",
    "    'no2': standard_scaler, \n",
    "    'o3': standard_scaler,\n",
    "    'so2': standard_scaler, \n",
    "    'pm2_5': standard_scaler, \n",
    "    'pm10': standard_scaler, \n",
    "    'nh3': standard_scaler\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc23c8b",
   "metadata": {},
   "source": [
    "Training data is created from feature views in Hopsworks. Feature views are logical views over sets of features. Normally they are created by joining together different feature groups. Since we only have one here though it's a little different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c40c901a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/14486/fs/14406/fv/aqi_chicago_60603_fv/version/1\n"
     ]
    }
   ],
   "source": [
    "fv_name = f'{fg_name}_fv'\n",
    "\n",
    "try:\n",
    "    feature_view = fs.get_feature_view(name=fv_name, version=1)\n",
    "except: \n",
    "    feature_view = fs.create_feature_view(\n",
    "    name=fv_name,\n",
    "    version=1,\n",
    "    description='feature view for creating training data',\n",
    "    query=ds_query,\n",
    "    labels=['aqi'],\n",
    "    transformation_functions=transformation_functions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95be452",
   "metadata": {},
   "source": [
    "Now let's get the earliest and latest dates in the dataset to split our data into a training and testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b238587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-13 12:00:00 2020-11-27 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "newest_date = pd.to_datetime(fs.sql(f\"SELECT MAX(`datetime`) FROM `{fg_name}_1`\", online=True).values[0][0])\n",
    "oldest_date = pd.to_datetime(fs.sql(f\"SELECT MIN(`datetime`) FROM `{fg_name}_1`\", online=True).values[0][0])\n",
    "\n",
    "print(newest_date, oldest_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c53c0304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-27 00:00:00 2022-12-14 12:00:00 2022-12-14 13:00:00 2023-01-13 12:00:00\n"
     ]
    }
   ],
   "source": [
    "train_start = oldest_date\n",
    "train_end = newest_date - datetime.timedelta(days=30)\n",
    "\n",
    "test_start = train_end + datetime.timedelta(hours=1)\n",
    "test_end = newest_date\n",
    "\n",
    "print(train_start, train_end, test_start, test_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc13a6",
   "metadata": {},
   "source": [
    "We'll give ourselves roughly 2 years of training data and 1 month of testing data. Now convert to a format Hopsworks can understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fd99f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20201127000000 20221214120000 20221214130000 20230113120000\n"
     ]
    }
   ],
   "source": [
    "train_start_str = train_start.strftime(\"%Y%m%d%H%M%S\")\n",
    "train_end_str = train_end.strftime(\"%Y%m%d%H%M%S\")\n",
    "test_start_str = test_start.strftime(\"%Y%m%d%H%M%S\")\n",
    "test_end_str = test_end.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "print(train_start_str, train_end_str, test_start_str, test_end_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aef2a63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aqi data for training 2020-11-27 00:00:00 to 2022-12-14 12:00:00\n"
     ]
    }
   ],
   "source": [
    "print(f'aqi data for training {train_start} to {train_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5864ed2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/14486/jobs/named/aqi_chicago_60603_fv_1_1_create_fv_td_17012023215333/executions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `1`.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'testing_end' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m train_d, train_d_job \u001b[38;5;241m=\u001b[39m feature_view\u001b[38;5;241m.\u001b[39mcreate_training_data(\n\u001b[1;32m      3\u001b[0m         start_time \u001b[38;5;241m=\u001b[39m train_start_str,\n\u001b[1;32m      4\u001b[0m         end_time \u001b[38;5;241m=\u001b[39m train_end_str,    \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m         write_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m},\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Create training datasets based event time filter\u001b[39;00m\n\u001b[1;32m     12\u001b[0m test_d, test_d_job \u001b[38;5;241m=\u001b[39m feature_view\u001b[38;5;241m.\u001b[39mcreate_training_data(\n\u001b[1;32m     13\u001b[0m         start_time \u001b[38;5;241m=\u001b[39m test_start_str,\n\u001b[1;32m     14\u001b[0m         end_time \u001b[38;5;241m=\u001b[39m test_end_str,    \n\u001b[0;32m---> 15\u001b[0m         description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maqi data for testing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_start\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtesting_end\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m         data_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m         coalesce \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m         write_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m},\n\u001b[1;32m     19\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testing_end' is not defined"
     ]
    }
   ],
   "source": [
    "# Create training datasets based event time filter\n",
    "train_d, train_d_job = feature_view.create_training_data(\n",
    "        start_time = train_start_str,\n",
    "        end_time = train_end_str,    \n",
    "        description = f'aqi data for training {train_start} to {train_end}',\n",
    "        data_format = \"csv\",\n",
    "        coalesce = True,\n",
    "        write_options = {'wait_for_job': False},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42cbf9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/14486/jobs/named/aqi_chicago_60603_fv_1_2_create_fv_td_17012023215418/executions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `2`.\n"
     ]
    }
   ],
   "source": [
    "# Create testing datasets based event time filter\n",
    "test_d, test_d_job = feature_view.create_training_data(\n",
    "        start_time = test_start_str,\n",
    "        end_time = test_end_str,    \n",
    "        description = f'aqi data for testing {test_start} to {test_end}',\n",
    "        data_format = \"csv\",\n",
    "        coalesce = True,\n",
    "        write_options = {'wait_for_job': False},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8c0d5",
   "metadata": {},
   "source": [
    "Now that the train and test data set views have been created, we can access them like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e8dc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = feature_view.get_training_data(1)\n",
    "test_x, test_y = feature_view.get_training_data(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287f661d",
   "metadata": {},
   "source": [
    "Now we have a dataframe for each train and test x and y! Simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9522defa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>so2</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>pm10</th>\n",
       "      <th>nh3</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.161839</td>\n",
       "      <td>-0.303810</td>\n",
       "      <td>0.411643</td>\n",
       "      <td>-0.807920</td>\n",
       "      <td>-0.412964</td>\n",
       "      <td>-0.434698</td>\n",
       "      <td>-0.351544</td>\n",
       "      <td>0.110326</td>\n",
       "      <td>2021-11-02T04:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.667730</td>\n",
       "      <td>-0.143022</td>\n",
       "      <td>1.524082</td>\n",
       "      <td>-1.386293</td>\n",
       "      <td>0.040377</td>\n",
       "      <td>-0.371978</td>\n",
       "      <td>-0.225976</td>\n",
       "      <td>0.723985</td>\n",
       "      <td>2021-11-02T20:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.082379</td>\n",
       "      <td>-0.255417</td>\n",
       "      <td>-0.084660</td>\n",
       "      <td>-0.314349</td>\n",
       "      <td>-0.227830</td>\n",
       "      <td>-0.686437</td>\n",
       "      <td>-0.626309</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>2021-11-02T18:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.295705</td>\n",
       "      <td>0.528229</td>\n",
       "      <td>1.866102</td>\n",
       "      <td>-1.583492</td>\n",
       "      <td>-0.213589</td>\n",
       "      <td>0.184770</td>\n",
       "      <td>0.439669</td>\n",
       "      <td>1.404895</td>\n",
       "      <td>2021-11-02T23:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.225936</td>\n",
       "      <td>0.458502</td>\n",
       "      <td>1.832150</td>\n",
       "      <td>-1.580905</td>\n",
       "      <td>-0.073552</td>\n",
       "      <td>0.051597</td>\n",
       "      <td>0.287772</td>\n",
       "      <td>1.350254</td>\n",
       "      <td>2021-11-02T22:00:00.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         co        no       no2        o3       so2     pm2_5      pm10  \\\n",
       "0  0.161839 -0.303810  0.411643 -0.807920 -0.412964 -0.434698 -0.351544   \n",
       "1  0.667730 -0.143022  1.524082 -1.386293  0.040377 -0.371978 -0.225976   \n",
       "2 -0.082379 -0.255417 -0.084660 -0.314349 -0.227830 -0.686437 -0.626309   \n",
       "3  1.295705  0.528229  1.866102 -1.583492 -0.213589  0.184770  0.439669   \n",
       "4  1.225936  0.458502  1.832150 -1.580905 -0.073552  0.051597  0.287772   \n",
       "\n",
       "        nh3                  datetime  \n",
       "0  0.110326  2021-11-02T04:00:00.000Z  \n",
       "1  0.723985  2021-11-02T20:00:00.000Z  \n",
       "2  0.001044  2021-11-02T18:00:00.000Z  \n",
       "3  1.404895  2021-11-02T23:00:00.000Z  \n",
       "4  1.350254  2021-11-02T22:00:00.000Z  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8c1e2a",
   "metadata": {},
   "source": [
    "Now we can bring in Prophet and train a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ecada287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from prophet import Prophet\n",
    "\n",
    "# m = Prophet()\n",
    "train_x.datetime = pd.to_datetime(train_x.datetime, utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7371a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2021-11-02 04:00:00+00:00\n",
       "1       2021-11-02 20:00:00+00:00\n",
       "2       2021-11-02 18:00:00+00:00\n",
       "3       2021-11-02 23:00:00+00:00\n",
       "4       2021-11-02 22:00:00+00:00\n",
       "                   ...           \n",
       "17756   2021-05-20 01:00:00+00:00\n",
       "17757   2021-05-20 05:00:00+00:00\n",
       "17758   2021-05-20 06:00:00+00:00\n",
       "17759   2021-05-20 00:00:00+00:00\n",
       "17760   2021-05-20 10:00:00+00:00\n",
       "Name: datetime, Length: 17761, dtype: datetime64[ns, UTC]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3fd8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
